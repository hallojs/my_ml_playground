{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VV_ZlSFz_Nfb"
   },
   "source": [
    "# MNIST DP-SGD Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Jvqj7hz_b2P"
   },
   "source": [
    "## Imports and Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24089,
     "status": "ok",
     "timestamp": 1586599063472,
     "user": {
      "displayName": "jonas sander",
      "photoUrl": "",
      "userId": "00193758946461779324"
     },
     "user_tz": -120
    },
    "id": "ecJsF0D9CmkH",
    "outputId": "39a74b54-88cc-4fae-bc85-41f8ee8bec2e"
   },
   "outputs": [],
   "source": [
    "\"\"\"Evaluate the DP-SGD optimizer using TF 1.x.\n",
    "\n",
    "Code of the Notebook is based on\n",
    "https://github.com/tensorflow/privacy/blob/master/tutorials/\n",
    "mnist_dpsgd_tutorial_keras.py. For a quick walktrough see\n",
    "https://github.com/tensorflow/privacy/tree/master/tutorials/walkthrough.\n",
    "\n",
    "Attributes\n",
    "----------\n",
    "GradientDescentOptimizer : tf.train.GradientDescentOptimizer\n",
    "    Non-DP optimizer for the training.\n",
    "\n",
    "License of the code underlying this notebook\n",
    "--------------------------------------------\n",
    "Copyright 2019, The TensorFlow Authors.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "     http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# set tensorlfow version in google colab\n",
    "try:\n",
    "  %tensorflow_version 1.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "# used to measure the privacy gurantee\n",
    "from tensorflow_privacy.privacy.analysis.rdp_accountant import compute_rdp\n",
    "from tensorflow_privacy.privacy.analysis.rdp_accountant import \\\n",
    "    get_privacy_spent\n",
    "\n",
    "# optimizer used for the privacy-preserving training\n",
    "from tensorflow_privacy.privacy.optimizers.dp_optimizer import \\\n",
    "    DPGradientDescentGaussianOptimizer\n",
    "\n",
    "GradientDescentOptimizer = tf.train.GradientDescentOptimizer\n",
    "\n",
    "# mount google drive\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Epsilon Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24089,
     "status": "ok",
     "timestamp": 1586599063472,
     "user": {
      "displayName": "jonas sander",
      "photoUrl": "",
      "userId": "00193758946461779324"
     },
     "user_tz": -120
    },
    "id": "ecJsF0D9CmkH",
    "outputId": "39a74b54-88cc-4fae-bc85-41f8ee8bec2e"
   },
   "outputs": [],
   "source": [
    "def compute_epsilon(noise_multiplier, minibatches, epochs):\n",
    "  \"\"\"Computes epsilon value for given hyperparameters.\n",
    "\n",
    "      Epsilon describes the strength of our privacy guarantee. In the case of\n",
    "      DP-ML, it gives a bound on how much the probability of a particular model\n",
    "      output can vary by including (or removing) a single training example. We\n",
    "      usually want it to be a small constant. However, this is only an upper\n",
    "      bound, and a large value of epsilon could still mean good practical\n",
    "      privacy. Interpreting this value could be quiet difficult.\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  float\n",
    "      Epsion-value for the expanded privacy budget.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  noise_multiplier : float\n",
    "      Ratio of the standard deviation to the clipping norm. Typically more\n",
    "      noise results in stronger privacy and often at the expense of utility.\n",
    "  minibatches : int\n",
    "      Number of samples used in each training step.\n",
    "  epochs : int\n",
    "      Number of training iterations.\n",
    "  \"\"\"\n",
    "  # Together with the noise multiplier are these the parameters which are\n",
    "  # relevant to measuring the potential privacy loss induced by the training.\n",
    "  #\n",
    "  # * sampling_probability: The probability of an individual training point\n",
    "  # being included in a minibatch.\n",
    "  # * steps: Number of steps the optimizer takes over the training data.\n",
    "  steps = epochs * 60000 // minibatches\n",
    "  sampling_probability = minibatches / 60000\n",
    "\n",
    "  if noise_multiplier == 0.0:\n",
    "    return float('inf')\n",
    "\n",
    "  # TODO: Understand the exact meaning of the orders parameter\n",
    "  # The exact meaning of the orders is not quite clear to me yet. For a rough\n",
    "  # description and a rule of thumb see the walkthrough.\n",
    "  orders = [1 + x / 10. for x in range(1, 100)] + list(range(12, 64))\n",
    "\n",
    "  # Rule of thump: Delta is set to 1e-5 because MNIST has 60000 training\n",
    "  # points (see the walktrough). Delta bounds the probability that our privacy\n",
    "  # guarantee do not hold.\n",
    "  rdp = compute_rdp(q=sampling_probability,\n",
    "                    noise_multiplier=noise_multiplier,\n",
    "                    steps=steps,\n",
    "                    orders=orders)\n",
    "\n",
    "  return get_privacy_spent(orders, rdp, target_delta=1e-5)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24089,
     "status": "ok",
     "timestamp": 1586599063472,
     "user": {
      "displayName": "jonas sander",
      "photoUrl": "",
      "userId": "00193758946461779324"
     },
     "user_tz": -120
    },
    "id": "ecJsF0D9CmkH",
    "outputId": "39a74b54-88cc-4fae-bc85-41f8ee8bec2e"
   },
   "outputs": [],
   "source": [
    "def load_mnist():\n",
    "  \"\"\"Loads MNIST and preprocesses to combine training and validation data.\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  tuple\n",
    "      (history of the training, runtime measurement, epsilon-value)\n",
    "  \"\"\"\n",
    "  train, test = tf.keras.datasets.mnist.load_data()\n",
    "  train_data, train_labels = train\n",
    "  test_data, test_labels = test\n",
    "\n",
    "  train_data = np.array(train_data, dtype=np.float32) / 255\n",
    "  test_data = np.array(test_data, dtype=np.float32) / 255\n",
    "\n",
    "  train_data = train_data.reshape(train_data.shape[0], 28, 28, 1)\n",
    "  test_data = test_data.reshape(test_data.shape[0], 28, 28, 1)\n",
    "\n",
    "  train_labels = np.array(train_labels, dtype=np.int32)\n",
    "  test_labels = np.array(test_labels, dtype=np.int32)\n",
    "\n",
    "  train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=10)\n",
    "  test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=10)\n",
    "\n",
    "  assert train_data.min() == 0.\n",
    "  assert train_data.max() == 1.\n",
    "  assert test_data.min() == 0.\n",
    "  assert test_data.max() == 1.\n",
    "\n",
    "  return train_data, train_labels, test_data, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  from tensorflow.keras import Sequential\n",
    "  from tensorflow.keras.layers import Conv2D\n",
    "  from tensorflow.keras.layers import MaxPool2D\n",
    "  from tensorflow.keras.layers import Flatten\n",
    "  from tensorflow.keras.layers import Dense\n",
    "  \n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(16, 8, strides=2, padding='same', activation='relu', \n",
    "                   input_shape=(28, 28, 1)))\n",
    "  model.add(MaxPool2D(2, 1))\n",
    "  model.add(Conv2D(32, 4, strides=2, padding='valid', activation='relu'))\n",
    "  model.add(MaxPool2D(2, 1))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(32, activation='relu'))\n",
    "  model.add(Dense(10))\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model: SGD or DP-SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24089,
     "status": "ok",
     "timestamp": 1586599063472,
     "user": {
      "displayName": "jonas sander",
      "photoUrl": "",
      "userId": "00193758946461779324"
     },
     "user_tz": -120
    },
    "id": "ecJsF0D9CmkH",
    "outputId": "39a74b54-88cc-4fae-bc85-41f8ee8bec2e"
   },
   "outputs": [],
   "source": [
    "def main(dpsgd, learning_rate, noise_multiplier, l2_norm_clip, minibatches,\n",
    "         epochs, microbatches, callbacks=None, verbose=1):\n",
    "  \"\"\"Define, train and compute the used privacy budget of the keras model.\n",
    "\n",
    "  Raises\n",
    "  ------\n",
    "  ValueError\n",
    "      The number of microbatches must divide the batch size.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  dpsgd : bool\n",
    "      If True, train with DP-SGD. If False, train with vanilla SGD.\n",
    "  learning_rate : float\n",
    "      Learning rate for training.\n",
    "  noise_multiplier : float\n",
    "      Ratio of the standard deviation to the clipping norm. Typically more\n",
    "      noise results in stronger privacy and often at the expense of utility.\n",
    "  l2_norm_clip : float\n",
    "      Attribute gives the maximum Euclidean norm of each individual gradient\n",
    "      that is computed on an individual training example from a minibatch. This\n",
    "      parameter is used to bound the optimizer's sensitivity to individual\n",
    "      training points.\n",
    "  minibatches : int\n",
    "      Number of samples used in each training step.\n",
    "  epochs : int\n",
    "      Number of epochs used for the training.\n",
    "  microbatches : int\n",
    "      Number of microbatches (must be evently divide batch size). In practice\n",
    "      clipping gradients for each exampe indivdudally can strongly degrade the\n",
    "      performance because instead of parallelizing at the granularity of\n",
    "      minibatches the computations must be performed for each example. Rather\n",
    "      than clipping gradients per example we clip them on the basis of\n",
    "      microbatches. In this way is the number of microbatches a trade-off\n",
    "      parameter between privacy and utility (small number -> higher privacy,\n",
    "      number closer to size of minibatches -> higher utility).\n",
    "  verbose : int, optional\n",
    "      Verbose parameter of the TF fit function.\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  tuple\n",
    "      Training history, training time, epsilon value (see compute_epsilon())\n",
    "  \"\"\"\n",
    "  if dpsgd and minibatches % microbatches != 0:\n",
    "    raise ValueError('Number of microbatches should divide evenly minibatches')\n",
    "\n",
    "  # Load training and test data.\n",
    "  train_data, train_labels, test_data, test_labels = load_mnist()\n",
    "\n",
    "  # Define a sequential Keras model\n",
    "  model = create_model()\n",
    "\n",
    "  if dpsgd:\n",
    "    optimizer = DPGradientDescentGaussianOptimizer(\n",
    "        l2_norm_clip=l2_norm_clip,\n",
    "        noise_multiplier=noise_multiplier,\n",
    "        num_microbatches=microbatches,\n",
    "        learning_rate=learning_rate)\n",
    "    # Compute vector of per-example loss rather than its mean over a minibatch.\n",
    "    # The optimizers needs the loss per example in order to compute the\n",
    "    # gradients per example (rather than per minibatch) and clip/noise the\n",
    "    # gradient of each example individually.\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(\n",
    "        from_logits=True, reduction=tf.losses.Reduction.NONE)\n",
    "  else:\n",
    "    optimizer = GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "  # Compile model with Keras\n",
    "  model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "  # Train model with Keras and measure training time\n",
    "  start = timer()\n",
    "  history = model.fit(train_data[:1000], train_labels[:1000],\n",
    "                      epochs=epochs,\n",
    "                      validation_data=(test_data[:1000], test_labels[:1000]),\n",
    "                      batch_size=minibatches,\n",
    "                      verbose=verbose,\n",
    "                      callbacks=callbacks)\n",
    "  end = timer()\n",
    "\n",
    "  training_time = end - start  # time in seconds\n",
    "\n",
    "  # Compute the privacy budget expended\n",
    "  epsilon = -42\n",
    "  if dpsgd:\n",
    "    epsilon = compute_epsilon(noise_multiplier, minibatches, epochs)\n",
    "\n",
    "  return history, training_time, epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qcX9xItv_i_K"
   },
   "source": [
    "## Lets just fit a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "class TimeHistory(tf.keras.callbacks.Callback):\n",
    "  def on_train_begin(self, logs={}):\n",
    "      self.times = []\n",
    "\n",
    "  def on_epoch_begin(self, batch, logs={}):\n",
    "      self.epoch_time_start = time.time()\n",
    "\n",
    "  def on_epoch_end(self, batch, logs={}):\n",
    "      self.times.append(time.time() - self.epoch_time_start)\n",
    "\n",
    "# --- Hyperparamater\n",
    "dpsgd = True\n",
    "learning_rate = 0.15\n",
    "noise_multiplier = 1.1\n",
    "l2_norm_clip = 1.0\n",
    "# For the DP Optimizer the size of the minibatches must divide the number of\n",
    "# training samples!\n",
    "minibatches = 125\n",
    "epochs = 2\n",
    "microbatches = 125\n",
    "verbose=1\n",
    "\n",
    "# --- Callbacks\n",
    "time_callback = TimeHistory()\n",
    "callbacks = [time_callback]\n",
    "\n",
    "# tensorboard callback does not work with dp optimizer, but you can use this\n",
    "# code to optimize non-dp models\n",
    "#if !dpsgd:\n",
    "#  board_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,\n",
    "#                                                  histogram_freq=1,\n",
    "#                                                  update_freq='epoch',\n",
    "#                                                  profile_batch=0)\n",
    "#  callbacks.append(board_callback)\n",
    "#  %tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4170617,
     "status": "ok",
     "timestamp": 1586450366656,
     "user": {
      "displayName": "jonas sander",
      "photoUrl": "",
      "userId": "00193758946461779324"
     },
     "user_tz": -120
    },
    "id": "mBWP7o5atjWL",
    "outputId": "043c4048-74df-4055-fc0d-8a1bdcf616df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/clip_ops.py:301: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/2\n",
      "1000/1000 [==============================] - 5s 5ms/sample - loss: 2.3011 - acc: 0.1460 - val_loss: 2.2860 - val_acc: 0.1640\n",
      "Epoch 2/2\n",
      "1000/1000 [==============================] - 3s 3ms/sample - loss: 2.2730 - acc: 0.1900 - val_loss: 2.2631 - val_acc: 0.2270\n",
      "Training time:  9.018492429051548\n",
      "For delta=1e-5, the current epsilon is: 0.93\n"
     ]
    }
   ],
   "source": [
    "# Train the keras model and compute the used privacy budget.\n",
    "_, training_time, epsilon = main(dpsgd, learning_rate, noise_multiplier,\n",
    "                                 l2_norm_clip, minibatches, epochs,\n",
    "                                 microbatches, callbacks)\n",
    "\n",
    "print('Training time: ', training_time)\n",
    "if dpsgd:\n",
    "  print('For delta=1e-5, the current epsilon is: %.2f' % epsilon)\n",
    "else:\n",
    "  print('Trained with vanilla non-private SGD optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.984344959259033, 2.5537402629852295]\n"
     ]
    }
   ],
   "source": [
    "print(time_callback.times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YPdFsuIN_nH_"
   },
   "source": [
    "## Evaluate DP-SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17784216,
     "status": "ok",
     "timestamp": 1586442692828,
     "user": {
      "displayName": "jonas sander",
      "photoUrl": "",
      "userId": "00193758946461779324"
     },
     "user_tz": -120
    },
    "id": "jb6oPVWE9B0Y",
    "outputId": "a477fcc7-1aad-4be7-8bd8-20578db34669"
   },
   "outputs": [],
   "source": [
    "# We evaluate the DP-SGD with the following different\n",
    "# hyperparameters in terms of epsilon, accuracy and running time. We run each\n",
    "# each hyperparameter configuration (run) in a loop of 3 iterations.\n",
    "\n",
    "dps = [False, True, True, True]\n",
    "learning_rates = [0.1, 0.25, 0.15, 0.25]\n",
    "noise_multipliers = [1.3, 1.1, 0.7]\n",
    "clipping_thresholds = [1.5, 1, 1.5]\n",
    "minibatches = 250\n",
    "microbatches = 250\n",
    "epochs = [20, 15, 60, 45]\n",
    "\n",
    "# a running index\n",
    "dp_idx = -1\n",
    "# save the hyperparameters of each iteration in a list\n",
    "rows = []\n",
    "for idx, dp in enumerate(dps):\n",
    "  if dp:\n",
    "    dp_idx += 1\n",
    "\n",
    "  for i in range(3):\n",
    "    print('Run: ', idx, ' - Loop: ', i)\n",
    "\n",
    "    history, training_time, epsilon = main(dp, learning_rates[idx],\n",
    "                                           noise_multipliers[dp_idx],\n",
    "                                           clipping_thresholds[dp_idx],\n",
    "                                           minibatches, epochs[idx],\n",
    "                                           microbatches, 0)\n",
    "  \n",
    "    accuracy = history.history['val_acc'][-1]\n",
    "  \n",
    "    # save the hyperparameters per row in a dict\n",
    "    row = {'dp': dp,\n",
    "           'learning_rate': learning_rates[idx],\n",
    "           'noise_multiplier': noise_multipliers[dp_idx],\n",
    "           'clipping_threshols': clipping_thresholds[dp_idx],\n",
    "           'minibatches': minibatches,\n",
    "           'microbatches': microbatches,\n",
    "           'epochs': epochs[idx],\n",
    "           'epsilon': epsilon,\n",
    "           'accuracy': accuracy,\n",
    "           'training_time': training_time}\n",
    "\n",
    "    rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 673,
     "status": "ok",
     "timestamp": 1586599112825,
     "user": {
      "displayName": "jonas sander",
      "photoUrl": "",
      "userId": "00193758946461779324"
     },
     "user_tz": -120
    },
    "id": "K6WT4kmPfA7U",
    "outputId": "f322ad05-7639-450d-b3ae-6fc1230b34bf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dp</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>noise_multiplier</th>\n",
       "      <th>clipping_threshols</th>\n",
       "      <th>minibatches</th>\n",
       "      <th>microbatches</th>\n",
       "      <th>epochs</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>training_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>0.537926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>0.313726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>0.312303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>15</td>\n",
       "      <td>1.179901</td>\n",
       "      <td>0.9506</td>\n",
       "      <td>17.198169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>15</td>\n",
       "      <td>1.179901</td>\n",
       "      <td>0.9473</td>\n",
       "      <td>17.125886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>15</td>\n",
       "      <td>1.179901</td>\n",
       "      <td>0.9509</td>\n",
       "      <td>17.115841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>60</td>\n",
       "      <td>2.969930</td>\n",
       "      <td>0.9679</td>\n",
       "      <td>68.369128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>60</td>\n",
       "      <td>2.969930</td>\n",
       "      <td>0.9639</td>\n",
       "      <td>68.144310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>60</td>\n",
       "      <td>2.969930</td>\n",
       "      <td>0.9656</td>\n",
       "      <td>68.915586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>45</td>\n",
       "      <td>7.009134</td>\n",
       "      <td>0.9695</td>\n",
       "      <td>52.453361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>45</td>\n",
       "      <td>7.009134</td>\n",
       "      <td>0.9706</td>\n",
       "      <td>54.237840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>45</td>\n",
       "      <td>7.009134</td>\n",
       "      <td>0.9685</td>\n",
       "      <td>53.504667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dp  learning_rate  noise_multiplier  ...   epsilon  accuracy  training_time\n",
       "Run                                          ...                                   \n",
       "0    False           0.10               NaN  ...       NaN    0.9896       0.537926\n",
       "0    False           0.10               NaN  ...       NaN    0.9896       0.313726\n",
       "0    False           0.10               NaN  ...       NaN    0.9908       0.312303\n",
       "1     True           0.25               1.3  ...  1.179901    0.9506      17.198169\n",
       "1     True           0.25               1.3  ...  1.179901    0.9473      17.125886\n",
       "1     True           0.25               1.3  ...  1.179901    0.9509      17.115841\n",
       "2     True           0.15               1.1  ...  2.969930    0.9679      68.369128\n",
       "2     True           0.15               1.1  ...  2.969930    0.9639      68.144310\n",
       "2     True           0.15               1.1  ...  2.969930    0.9656      68.915586\n",
       "3     True           0.25               0.7  ...  7.009134    0.9695      52.453361\n",
       "3     True           0.25               0.7  ...  7.009134    0.9706      54.237840\n",
       "3     True           0.25               0.7  ...  7.009134    0.9685      53.504667\n",
       "\n",
       "[12 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save/load and clean up df\n",
    "#df.to_pickle('/content/drive/My Drive/df.pkl')\n",
    "df = pd.read_pickle('/content/drive/My Drive/df.pkl')\n",
    "df.loc[df.dp==False, ['epsilon', 'noise_multiplier', 'clipping_threshols']] = np.nan\n",
    "df['Run'] = np.array([[i]*3 for i in range(4)]).flatten()\n",
    "df = df.set_index('Run')\n",
    "df.loc[:, 'training_time'] /= 60\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 950,
     "status": "ok",
     "timestamp": 1586599116309,
     "user": {
      "displayName": "jonas sander",
      "photoUrl": "",
      "userId": "00193758946461779324"
     },
     "user_tz": -120
    },
    "id": "qLjZXRmBgJPL",
    "outputId": "f92f4771-2ebb-4d5a-f841-74ed61de26c9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>training_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.334690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002104</td>\n",
       "      <td>0.002619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002079</td>\n",
       "      <td>0.005793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001083</td>\n",
       "      <td>0.016797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     accuracy  training_time\n",
       "Run                         \n",
       "0    0.000700       0.334690\n",
       "1    0.002104       0.002619\n",
       "2    0.002079       0.005793\n",
       "3    0.001083       0.016797"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the relative standard derivation\n",
    "(df.loc[:,['accuracy', 'training_time']].std(level='Run')/\n",
    "df.loc[:,['accuracy', 'training_time']].mean(level='Run'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 439,
     "status": "ok",
     "timestamp": 1586599118369,
     "user": {
      "displayName": "jonas sander",
      "photoUrl": "",
      "userId": "00193758946461779324"
     },
     "user_tz": -120
    },
    "id": "XpSrv_yagFh5",
    "outputId": "501bd50a-b45d-4c95-bb1a-04d6a09f90ef"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dp</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>noise_multiplier</th>\n",
       "      <th>clipping_threshols</th>\n",
       "      <th>minibatches</th>\n",
       "      <th>microbatches</th>\n",
       "      <th>epochs</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>training_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.387985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>15</td>\n",
       "      <td>1.179901</td>\n",
       "      <td>0.949600</td>\n",
       "      <td>17.146632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>60</td>\n",
       "      <td>2.969930</td>\n",
       "      <td>0.965800</td>\n",
       "      <td>68.476342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>250</td>\n",
       "      <td>250</td>\n",
       "      <td>45</td>\n",
       "      <td>7.009134</td>\n",
       "      <td>0.969533</td>\n",
       "      <td>53.398623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dp  learning_rate  noise_multiplier  ...   epsilon  accuracy  training_time\n",
       "Run                                          ...                                   \n",
       "0    False           0.10               NaN  ...       NaN  0.990000       0.387985\n",
       "1     True           0.25               1.3  ...  1.179901  0.949600      17.146632\n",
       "2     True           0.15               1.1  ...  2.969930  0.965800      68.476342\n",
       "3     True           0.25               0.7  ...  7.009134  0.969533      53.398623\n",
       "\n",
       "[4 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the mean of each run\n",
    "df = df.mean(level='Run')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 441,
     "status": "ok",
     "timestamp": 1586599120664,
     "user": {
      "displayName": "jonas sander",
      "photoUrl": "",
      "userId": "00193758946461779324"
     },
     "user_tz": -120
    },
    "id": "ZKEhigvl_7lD",
    "outputId": "83a47b9d-0681-4467-e374-347843e4c62b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrr}\n",
      "\\toprule\n",
      "    dp &  learning\\_rate &  noise\\_multiplier &  clipping\\_threshols &  epochs &   epsilon &  accuracy &  training\\_time \\\\\n",
      " False &           0.10 &               NaN &                 NaN &      20 &       NaN &  0.990000 &       0.387985 \\\\\n",
      "\\midrule\n",
      "  True &           0.25 &               1.3 &                 1.5 &      15 &  1.179901 &  0.949600 &      17.146632 \\\\\n",
      "  True &           0.15 &               1.1 &                 1.0 &      60 &  2.969930 &  0.965800 &      68.476342 \\\\\n",
      "  True &           0.25 &               0.7 &                 1.5 &      45 &  7.009134 &  0.969533 &      53.398623 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(labels=['minibatches', 'microbatches'], axis=1)\n",
    "print(df.to_latex(index=False))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPJ6sH58rXL9yEO2V4YPuBF",
   "collapsed_sections": [],
   "name": "mnist_dpsgd",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
